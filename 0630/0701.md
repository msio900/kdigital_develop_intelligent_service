# 0701

## 1. classification

> 주피터 노트북 팁 run all below/run all avobe

1. null이 있는지 없는지 확인...
   1. 

api를 확인하고 학습하면서 할 필요가 있음.

### Logistic Regression

```python
from sklearn.linear_model import LogisticRegression

logR = LogisticRegression() # 모델 초기화
type(logR) # 범주형 모델 이름이 비슷하다고 헷갈리지 말라!! 아예 classification = LogisticRegression
sklearn.linear_model._logistic.LogisticRegression

logR.fit(X_train, Y_train)
C:\Python\Python36\lib\site-packages\sklearn\utils\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  return f(*args, **kwargs)
LogisticRegression()

logR.classes_
array([0, 1], dtype=int64)

logR.coef_ # 내가 넣은 항목마다 계수의 갯수가 생김.
array([[-0.84804181, -0.12789375,  0.26294701,  0.00288228]])
# 방정식이 한번 나오게 됨.

logR.score(X_train, Y_train)
0.6946107784431138

```

`probablity` : 

### 모델 평가

```python
y_pred=log.predict(x_train)
y_pred.shape, y_train.shape
((112,), (112,))

print(metrics.classification_report(y_train, y_pred))
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        36
           1       0.95      0.92      0.93        38
           2       0.92      0.95      0.94        38

    accuracy                           0.96       112
   macro avg       0.96      0.96      0.96       112
weighted avg       0.96      0.96      0.96       112

metrics.confusion_matrix(y_train, y_pred)
array([[36,  0,  0],
       [ 0, 35,  3],
       [ 0,  2, 36]], dtype=int64)
```

#### model Evaluation

1. 정밀도 : 모델이 True 라고 분류한 것중에서 실제 True 인 것의 비율
   1. 정밀도가 높으면 새로운 데이터에 적용이 힘듦
2. 재현율(Recall, Sensitivity, hit rate) : 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율
   1. 재현율이 높으면 적용은 잘되지만 너무 대충 때려 맞추는 게 되어버림...!
3. 정확도(Accuracy) : 모델이 실제와 예측 시 맞춘 비율, Data편중시 불명확,
4. F-score : Precision과 Recall과 조화평균, Accuracy 보완

밸런스가 맞지 않은 데이터는 f1-score로!!

#### Under fit, Overfit의 가운데 값을 찾아냄!


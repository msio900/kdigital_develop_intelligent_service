# 0630

## 어제의 복습

1. 선 지식(Knowledge)이 있어야 ML이 가능하다. (공부시간 대비 성적 예시)
2. 선형 수학을 이용해서 예측함.
3. ML과 DL의 차이점
   * 통계를 기반으로 논문을 쓰는데
   * 통계학의 발전 : 르네상스 시대, 논증법의 발전, 숫자-수학이 발전하기 시작 18세기
   * 지금 시대는 거의 모집단의 크기에 가까운 데이터가 있음에 방식의 변화가 생김.
4. 변수(Variables)
   * `X`(원인) : 독립변수, 예측변수, 입력변수
   * `Y`(결과) : 종속변수, 반응변수, 출력변수
   * 고정적인 **머신 러닝**은 규정이 있다. 

## 1. 선형대수학

>  [선형대수학 설명 유튜브 URI](https://www.youtube.com/watch?v=B9g6KlZ9i0k&list=PL127T2Zu76FuVMq1UQnZv9SG-GFIdZfLg&index=9&ab_channel=%EC%9D%B4%EC%83%81%EC%97%BDMath)

## 3. 서비스 영역

### 피클의 사용

#### 바이너리 영역에 대해서

파일 모드 종류
r - 읽기모드 (디폴트)
w - 쓰기모드, 파일이 있으면 모든 내용을 삭제
x - 쓰기모드, 파일이 있으면 오류 발생
a - 쓰기모드, 파일이 있으면 뒤에 내용을 추가
+ - 읽기쓰기모드

t - 텍스트 모드, 텍스트 문자 기록에 사용 (디폴트)
b - 바이너리 모드, 바이트단위 데이터 기록에 사용
파일 모드 사용예
f = open('file.txt', 'rt')
기본값으로 텍스트 읽기모드 (rt는 생략 가능)
f = open('file.txt', 'wb')
바이너리 쓰기모드
f = open('file.txt', 'r+t')
텍스트 읽기쓰기모드, 맨 앞에서부터 내용을 덮어쓴다. (파일이 없으면 오류 발생)
f = open('file.txt', 'w+t')
텍스트 읽기쓰기모드, 파일 내용을 다 지우고 다시 쓴다.
f = open('file.txt', 'a+t')

텍스트 읽기쓰기모드, 파일의 모든 내용을 남겨두고 맨 뒤에서부터 쓴다.

+가 포함된 파일모드는 모두 읽기쓰기모드이지만 기존 파일 내용을 처리하는 방식에 차이가 있다.

## 선형회귀

R^2 가 0과 1사이에 존재!

`((y_true - y_true.mean()) ** 2).sum()` 스코어가 어떻게 나오는지?!

아주 약간약간씩 바뀜...ㅠㅠㅠㅠ

## [실습]

> 머신러닝 실습
>
> 데이터는 Kaggle에 있는 New York City taxi Trip Duration
>
> [kaggle URI](https://www.kaggle.com/c/nyc-taxi-trip-duration/data)

1. 정보 단계
   1. 문제와 답의 column 선택 : `X`와 `Y`를 선택
   2. `X`는 n개 여도 가능(x를 2개 이상)
   3. 선택 column의 문제 여부 판단(결측치, object 인지 판단)
2. 교육 단계
   1. 데이터를 split을 해야함. 
   2. 교육을 함. linear regression
   3. model 점수 확인
3. 서비스 단계
   1. `pickle`로 저장, 불러오기
   2. predict
4. 다 끝나고 나면 분석을 해야함.
   1. 분석 : model의 점수를 보고 자신의 의견을 기록해서 맨 위에 적기!

분산은 



## Classification

supervised 모델 : 지도학습

1. 머머 이거나 머머 이거나
2. 여러 개로 나눔.

### Logistic Regression

* 일종의 확률 그래프로 나옴.
* 아웃풋이 되는 값을 변형 시킴.
* 직선이나 곡선을 찾는 것은 맞음.
* 카테고리로 답변이 나옴

